{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWAfNEcj7xRe/oSBhikAVO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GhazalehKeyvani/Data-Science-Exercises/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Minimom Liklihood Distance**"
      ],
      "metadata": {
        "id": "Jr8ekyY1h1ct"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L-j2GjHycriM"
      },
      "outputs": [],
      "source": [
        "def levenshtein(s, t):\n",
        "    m, n = len(s), len(t)\n",
        "    D = [[0]*(n+1) for _ in range(m+1)]\n",
        "    for i in range(m+1):\n",
        "        D[i][0] = i\n",
        "    for j in range(n+1):\n",
        "        D[0][j] = j\n",
        "    for i in range(1, m+1):\n",
        "        for j in range(1, n+1):\n",
        "            cost = 0 if s[i-1] == t[j-1] else 1\n",
        "            D[i][j] = min(\n",
        "                D[i-1][j] + 1,      # deletion\n",
        "                D[i][j-1] + 1,      # insertion\n",
        "                D[i-1][j-1] + cost  # substitution/match\n",
        "            )\n",
        "    return D[m][n]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "levenshtein(\"leda\",\"deal\") == 3\n",
        "levenshtein(\"drive\",\"brief\") == 3\n",
        "levenshtein(\"drive\",\"divers\") == 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qq7XNDXcvfS",
        "outputId": "41770275-5eed-4cb7-8821-5dccb298c0d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def levenshtein_with_alignment(s, t):\n",
        "    m, n = len(s), len(t)\n",
        "    D = [[0]*(n+1) for _ in range(m+1)]\n",
        "    ptr = [[None]*(n+1) for _ in range(m+1)]  # '↖' diag, '↑' del, '←' ins\n",
        "\n",
        "    for i in range(m+1):\n",
        "        D[i][0] = i\n",
        "        ptr[i][0] = '↑' if i else None\n",
        "    for j in range(n+1):\n",
        "        D[0][j] = j\n",
        "        ptr[0][j] = '←' if j else None\n",
        "\n",
        "    for i in range(1, m+1):\n",
        "        for j in range(1, n+1):\n",
        "            cost = 0 if s[i-1] == t[j-1] else 1\n",
        "            choices = [\n",
        "                (D[i-1][j] + 1, '↑'),         # deletion\n",
        "                (D[i][j-1] + 1, '←'),         # insertion\n",
        "                (D[i-1][j-1] + cost, '↖')     # substitution/match\n",
        "            ]\n",
        "            D[i][j], ptr[i][j] = min(choices, key=lambda x: x[0])\n",
        "\n",
        "    # Backtrace\n",
        "    i, j = m, n\n",
        "    a_s, a_t, ops = [], [], []\n",
        "    while i > 0 or j > 0:\n",
        "        p = ptr[i][j]\n",
        "        if p == '↖':\n",
        "            a_s.append(s[i-1]); a_t.append(t[j-1])\n",
        "            ops.append(' ' if s[i-1] == t[j-1] else '*')\n",
        "            i -= 1; j -= 1\n",
        "        elif p == '↑':\n",
        "            a_s.append(s[i-1]); a_t.append('-')\n",
        "            ops.append('D'); i -= 1\n",
        "        elif p == '←':\n",
        "            a_s.append('-'); a_t.append(t[j-1])\n",
        "            ops.append('I'); j -= 1\n",
        "\n",
        "    return D[m][n], ''.join(reversed(a_s)), ''.join(reversed(ops)), ''.join(reversed(a_t))\n",
        "\n",
        "# Example:\n",
        "dist, s_aln, op, t_aln = levenshtein_with_alignment(\"leda\",\"deal\")\n",
        "print(dist)     # 3\n",
        "print(s_aln)    # leda\n",
        "print(op)       # * * *\n",
        "print(t_aln)    # deal\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMoIVN01c8qP",
        "outputId": "c63f9178-e9f1-4136-9174-601b370632bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "leda-\n",
            "* D I\n",
            "de-al\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def count_ngrams(corpus):\n",
        "    unigram_counts = defaultdict(int)\n",
        "    bigram_counts = defaultdict(int)\n",
        "\n",
        "    for sentence in corpus:\n",
        "        tokens = ['<s>'] + sentence + ['</s>']  # include start and end tokens\n",
        "        for i in range(len(tokens)):\n",
        "            unigram_counts[tokens[i]] += 1\n",
        "            if i < len(tokens) - 1:\n",
        "                bigram = (tokens[i], tokens[i+1])\n",
        "                bigram_counts[bigram] += 1\n",
        "\n",
        "    return unigram_counts, bigram_counts\n",
        "\n",
        "# Example corpus: list of tokenized sentences\n",
        "corpus = [\n",
        "    ['I', 'am', 'Sam'],\n",
        "    ['Sam', 'I', 'am'],\n",
        "    ['I', 'am', 'Sam'],\n",
        "    ['I', 'do', 'not', 'like', 'green', 'eggs', 'and', 'Sam']\n",
        "]\n",
        "\n",
        "# Count n-grams\n",
        "unigrams, bigrams = count_ngrams(corpus)\n",
        "\n",
        "# Display results\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in unigrams.items():\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "print(\"\\nBigram Counts:\")\n",
        "for bigram, count in bigrams.items():\n",
        "    print(f\"{bigram}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZoOvFfCdIj1",
        "outputId": "1ed33d47-db1f-4076-a51c-ca6ca2ee7546"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "<s>: 4\n",
            "I: 4\n",
            "am: 3\n",
            "Sam: 4\n",
            "</s>: 4\n",
            "do: 1\n",
            "not: 1\n",
            "like: 1\n",
            "green: 1\n",
            "eggs: 1\n",
            "and: 1\n",
            "\n",
            "Bigram Counts:\n",
            "('<s>', 'I'): 3\n",
            "('I', 'am'): 3\n",
            "('am', 'Sam'): 2\n",
            "('Sam', '</s>'): 3\n",
            "('<s>', 'Sam'): 1\n",
            "('Sam', 'I'): 1\n",
            "('am', '</s>'): 1\n",
            "('I', 'do'): 1\n",
            "('do', 'not'): 1\n",
            "('not', 'like'): 1\n",
            "('like', 'green'): 1\n",
            "('green', 'eggs'): 1\n",
            "('eggs', 'and'): 1\n",
            "('and', 'Sam'): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_email = [\n",
        "    [\"Hi\", \"John\", \",\", \"I\", \"hope\", \"you're\", \"doing\", \"well\", \".\"],\n",
        "    [\"Please\", \"find\", \"attached\", \"the\", \"report\", \"for\", \"last\", \"week\", \".\"],\n",
        "    [\"Let\", \"me\", \"know\", \"if\", \"you\", \"have\", \"any\", \"questions\", \".\"]\n",
        "]\n",
        "\n",
        "\n",
        "# Count n-grams\n",
        "unigrams, bigrams = count_ngrams(corpus_email)\n",
        "\n",
        "# Display results\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in unigrams.items():\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "print(\"\\nBigram Counts:\")\n",
        "for bigram, count in bigrams.items():\n",
        "    print(f\"{bigram}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1mEsaQHdmhi",
        "outputId": "ce73be3b-4346-4e60-d6f0-23975316ce60"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "<s>: 3\n",
            "Hi: 1\n",
            "John: 1\n",
            ",: 1\n",
            "I: 1\n",
            "hope: 1\n",
            "you're: 1\n",
            "doing: 1\n",
            "well: 1\n",
            ".: 3\n",
            "</s>: 3\n",
            "Please: 1\n",
            "find: 1\n",
            "attached: 1\n",
            "the: 1\n",
            "report: 1\n",
            "for: 1\n",
            "last: 1\n",
            "week: 1\n",
            "Let: 1\n",
            "me: 1\n",
            "know: 1\n",
            "if: 1\n",
            "you: 1\n",
            "have: 1\n",
            "any: 1\n",
            "questions: 1\n",
            "\n",
            "Bigram Counts:\n",
            "('<s>', 'Hi'): 1\n",
            "('Hi', 'John'): 1\n",
            "('John', ','): 1\n",
            "(',', 'I'): 1\n",
            "('I', 'hope'): 1\n",
            "('hope', \"you're\"): 1\n",
            "(\"you're\", 'doing'): 1\n",
            "('doing', 'well'): 1\n",
            "('well', '.'): 1\n",
            "('.', '</s>'): 3\n",
            "('<s>', 'Please'): 1\n",
            "('Please', 'find'): 1\n",
            "('find', 'attached'): 1\n",
            "('attached', 'the'): 1\n",
            "('the', 'report'): 1\n",
            "('report', 'for'): 1\n",
            "('for', 'last'): 1\n",
            "('last', 'week'): 1\n",
            "('week', '.'): 1\n",
            "('<s>', 'Let'): 1\n",
            "('Let', 'me'): 1\n",
            "('me', 'know'): 1\n",
            "('know', 'if'): 1\n",
            "('if', 'you'): 1\n",
            "('you', 'have'): 1\n",
            "('have', 'any'): 1\n",
            "('any', 'questions'): 1\n",
            "('questions', '.'): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_news = [\n",
        "    [\"The\", \"government\", \"announced\", \"new\", \"policies\", \"on\", \"climate\", \"change\", \".\"],\n",
        "    [\"Experts\", \"say\", \"the\", \"impact\", \"will\", \"be\", \"significant\", \".\"],\n",
        "    [\"Public\", \"reaction\", \"has\", \"been\", \"mixed\", \"so\", \"far\", \".\"]\n",
        "]\n",
        "\n",
        "\n",
        "# Count n-grams\n",
        "unigrams, bigrams = count_ngrams(corpus_news)\n",
        "\n",
        "# Display results\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in unigrams.items():\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "print(\"\\nBigram Counts:\")\n",
        "for bigram, count in bigrams.items():\n",
        "    print(f\"{bigram}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byM-d4fCd9iR",
        "outputId": "3a074993-a4d3-477b-9708-3bf8b9599e2b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "<s>: 3\n",
            "The: 1\n",
            "government: 1\n",
            "announced: 1\n",
            "new: 1\n",
            "policies: 1\n",
            "on: 1\n",
            "climate: 1\n",
            "change: 1\n",
            ".: 3\n",
            "</s>: 3\n",
            "Experts: 1\n",
            "say: 1\n",
            "the: 1\n",
            "impact: 1\n",
            "will: 1\n",
            "be: 1\n",
            "significant: 1\n",
            "Public: 1\n",
            "reaction: 1\n",
            "has: 1\n",
            "been: 1\n",
            "mixed: 1\n",
            "so: 1\n",
            "far: 1\n",
            "\n",
            "Bigram Counts:\n",
            "('<s>', 'The'): 1\n",
            "('The', 'government'): 1\n",
            "('government', 'announced'): 1\n",
            "('announced', 'new'): 1\n",
            "('new', 'policies'): 1\n",
            "('policies', 'on'): 1\n",
            "('on', 'climate'): 1\n",
            "('climate', 'change'): 1\n",
            "('change', '.'): 1\n",
            "('.', '</s>'): 3\n",
            "('<s>', 'Experts'): 1\n",
            "('Experts', 'say'): 1\n",
            "('say', 'the'): 1\n",
            "('the', 'impact'): 1\n",
            "('impact', 'will'): 1\n",
            "('will', 'be'): 1\n",
            "('be', 'significant'): 1\n",
            "('significant', '.'): 1\n",
            "('<s>', 'Public'): 1\n",
            "('Public', 'reaction'): 1\n",
            "('reaction', 'has'): 1\n",
            "('has', 'been'): 1\n",
            "('been', 'mixed'): 1\n",
            "('mixed', 'so'): 1\n",
            "('so', 'far'): 1\n",
            "('far', '.'): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ایمیل‌ها پر از ضمایر شخصی مثل \"I\" و \"you\" هستن.\n",
        "\n",
        "متن خبری بیشتر شامل اسم‌های رسمی و موضوعی مثل \"government\"، \"policies\"، \"climate\" هست.\n",
        "\n",
        "بی‌گرام‌های ایمیل بیشتر حالت دستوری و تعاملی دارن: \"Please find\", \"Let me\", \"you have\".\n",
        "\n",
        "بی‌گرام‌های خبری بیشتر ترکیب‌های موضوعی هستن: \"climate change\", \"impact will\", \"Public reaction\"."
      ],
      "metadata": {
        "id": "5YTU4dg5fO0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ELIZIA Chatbot**"
      ],
      "metadata": {
        "id": "46BQaB4zhpJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import random\n",
        "\n",
        "# ---------- reflection ----------\n",
        "REFLECTIONS = {\n",
        "    \"I\": \"YOU\", \"ME\": \"YOU\", \"MY\": \"YOUR\", \"MINE\": \"YOURS\",\n",
        "    \"AM\": \"ARE\", \"I'M\": \"YOU ARE\",\n",
        "    \"YOU\": \"I\", \"YOUR\": \"MY\", \"YOURS\": \"MINE\", \"ARE\": \"AM\"\n",
        "}\n",
        "\n",
        "_reflex_pattern = re.compile(r\"\\b(I'M|I|ME|MY|MINE|YOU|YOUR|YOURS|AM|ARE)\\b\")\n",
        "\n",
        "def reflect(text: str) -> str:\n",
        "    def _swap(m):\n",
        "        tok = m.group(1)\n",
        "        return REFLECTIONS.get(tok, tok)\n",
        "    return _reflex_pattern.sub(_swap, text)\n",
        "\n",
        "# ---------- rule engine ----------\n",
        "class Rule:\n",
        "    def __init__(self, pattern, responses, reflect_groups=None):\n",
        "        self.pattern = re.compile(pattern)\n",
        "        self.responses = responses\n",
        "        self.reflect_groups = set(reflect_groups or [])\n",
        "\n",
        "    def try_apply(self, text: str):\n",
        "        m = self.pattern.match(text)\n",
        "        if not m:\n",
        "            return None\n",
        "        # fill numbered placeholders {1}, {2}, ...\n",
        "        def fill(template: str) -> str:\n",
        "            out = template\n",
        "            for i in range(1, len(m.groups()) + 1):\n",
        "                g = m.group(i) or \"\"\n",
        "                g = g.strip()\n",
        "                if i in self.reflect_groups:\n",
        "                    g = reflect(g)\n",
        "                out = out.replace(f\"{{{i}}}\", g)\n",
        "            return out\n",
        "        return fill(random.choice(self.responses))\n",
        "\n",
        "# ---------- rule sets ----------\n",
        "ROGERIAN_RULES = [\n",
        "    # direct echoes with sentiment\n",
        "    Rule(r\".*\\bYOU ARE (DEPRESSED|SAD)\\b.*\", [\n",
        "        \"I AM SORRY TO HEAR YOU ARE {1}\",\n",
        "        \"WHY DO YOU THINK YOU ARE {1}\"\n",
        "    ]),\n",
        "    Rule(r\".*\\bI AM (.*)\", [\n",
        "        \"HOW LONG HAVE YOU BEEN {1}?\",\n",
        "        \"WHY ARE YOU {1}?\"\n",
        "    ], reflect_groups={1}),\n",
        "    Rule(r\".*\\bI FEEL (.*)\", [\n",
        "        \"DO YOU OFTEN FEEL {1}?\",\n",
        "        \"WHAT MAKES YOU FEEL {1}?\"\n",
        "    ], reflect_groups={1}),\n",
        "    Rule(r\".*\\bI WANT (?:TO )?(.*)\", [\n",
        "        \"WHAT WOULD IT MEAN IF YOU GOT {1}?\",\n",
        "        \"WHY DO YOU WANT {1}?\"\n",
        "    ], reflect_groups={1}),\n",
        "    Rule(r\".*\\bMY (.*)\", [\n",
        "        \"TELL ME MORE ABOUT YOUR {1}.\",\n",
        "        \"HOW DOES YOUR {1} MAKE YOU FEEL?\"\n",
        "    ], reflect_groups={1}),\n",
        "    Rule(r\".*\\bALWAYS\\b.*\", [\"CAN YOU THINK OF A SPECIFIC EXAMPLE?\"]),\n",
        "    Rule(r\".*\\bALL\\b.*\", [\"IN WHAT WAY?\"]),\n",
        "]\n",
        "\n",
        "TECH_SUPPORT_RULES = [\n",
        "    Rule(r\".*\\bERROR (\\d+)\\b.*\", [\n",
        "        \"I SEE ERROR {1}. WHEN DID THIS START?\",\n",
        "        \"ERROR {1} OCCURRED. DID YOU CHANGE ANY SETTINGS RECENTLY?\"\n",
        "    ]),\n",
        "    Rule(r\".*\\bDOES NOT WORK\\b.*\", [\n",
        "        \"WHAT EXACTLY DOES NOT WORK?\",\n",
        "        \"DO YOU SEE ANY ERROR MESSAGE?\"\n",
        "    ]),\n",
        "    Rule(r\".*\\b(CRASH|FREEZE|HANGS)\\b.*\", [\n",
        "        \"HOW OFTEN DOES IT {1}?\",\n",
        "        \"WHAT WERE YOU DOING WHEN IT STARTED TO {1}?\"\n",
        "    ]),\n",
        "    Rule(r\".*\\bINSTALL(ING|ATION)?\\b.*\", [\n",
        "        \"ARE YOU INSTALLING WITH ADMIN RIGHTS?\",\n",
        "        \"WHICH VERSION ARE YOU TRYING TO INSTALL?\"\n",
        "    ]),\n",
        "    Rule(r\".*\\bNETWORK\\b.*\", [\n",
        "        \"ARE YOU ON WIFI OR ETHERNET?\",\n",
        "        \"CAN YOU RESTART YOUR ROUTER AND TRY AGAIN?\"\n",
        "    ]),\n",
        "]\n",
        "\n",
        "DEFAULTS = [\n",
        "    \"PLEASE GO ON.\",\n",
        "    \"TELL ME MORE.\",\n",
        "    \"CAN YOU ELABORATE?\",\n",
        "    \"WHY DO YOU SAY THAT?\"\n",
        "]\n",
        "\n",
        "DOMAINS = {\n",
        "    \"rogerian\": ROGERIAN_RULES,\n",
        "    \"tech\": TECH_SUPPORT_RULES\n",
        "}\n",
        "\n",
        "def preprocess(user_text: str) -> str:\n",
        "    # Trim and uppercase; keep punctuation as-is.\n",
        "    return user_text.strip().upper()\n",
        "\n",
        "def eliza_reply(user_text: str, domain=\"rogerian\") -> str:\n",
        "    if not user_text or user_text.isspace():\n",
        "        return \"HELLO. HOW ARE YOU FEELING TODAY?\"\n",
        "    text = preprocess(user_text)\n",
        "\n",
        "    # First, do global pronoun substitutions for later echoes where needed\n",
        "    # (We will also reflect specific capture groups when rules request it.)\n",
        "    # Note: Many classic ELIZA implementations echo raw or reflected spans selectively.\n",
        "    rules = DOMAINS.get(domain, ROGERIAN_RULES)\n",
        "    for rule in rules:\n",
        "        resp = rule.try_apply(text)\n",
        "        if resp:\n",
        "            return resp\n",
        "    return random.choice(DEFAULTS)\n",
        "\n",
        "# ---- quick RE examples for backreferences (not used directly above) ----\n",
        "# pattern_backref = re.compile(r\"the (.*)er they were, the \\1er they will be\")\n",
        "# pattern_noncapture = re.compile(r\"(?:SOME|A FEW) (PEOPLE|CATS) LIKE SOME \\1\")\n"
      ],
      "metadata": {
        "id": "IOmvJCsieFh_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"ELIZA: HELLO. HOW ARE YOU FEELING TODAY?\")\n",
        "    domain = input(\"Choose domain (rogerian/tech): \").strip().lower()\n",
        "    if domain not in [\"rogerian\", \"tech\"]:\n",
        "        print(\"Using default domain: rogerian\")\n",
        "        domain = \"rogerian\"\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"YOU: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
        "            print(\"ELIZA: GOODBYE. TAKE CARE!\")\n",
        "            break\n",
        "        response = eliza_reply(user_input, domain=domain)\n",
        "        print(f\"ELIZA: {response}\")\n"
      ],
      "metadata": {
        "id": "HETfhwbOgbq8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkwTJlZRgzie",
        "outputId": "4b368621-b9d8-4ed4-e459-8cb2f19d62d1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ELIZA: HELLO. HOW ARE YOU FEELING TODAY?\n",
            "Choose domain (rogerian/tech): i like speek with you\n",
            "Using default domain: rogerian\n",
            "YOU: no\n",
            "ELIZA: TELL ME MORE.\n",
            "YOU: always i want speek with you\n",
            "ELIZA: WHY DO YOU WANT SPEEK WITH I?\n",
            "YOU: about my problems\n",
            "ELIZA: HOW DOES YOUR PROBLEMS MAKE YOU FEEL?\n",
            "YOU: nothing\n",
            "ELIZA: WHY DO YOU SAY THAT?\n",
            "YOU: exit\n",
            "ELIZA: GOODBYE. TAKE CARE!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "84F8tXTBg1zi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}